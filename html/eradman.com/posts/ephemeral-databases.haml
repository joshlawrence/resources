%h1 Ephemeral Postgres Databases

%p
  For some time proponents of unit testing have asserted that unit tests should
  not touch a real database. The standard practice was to mock these interactions
  at the level of language-native objects.  Does this rule apply if the database
  is in memory? Some realized that an in-process engine such as SQLite seemed to
  solve this problem nicely since the database can be run without touching the
  file system. This is how running Django tests might look

:codeblock
  :::python
  # settings_fast.py
  # run using
  #   python manage.py test --settings=settings_fast

  from settings import *

  DATABASES = {
     'default': {
          'ENGINE': 'django.db.backends.sqlite3',
          'NAME': ':memory:',
      }
  }

%h2 Automatic PG Creation and Teardown

%p
  Using an SQLite in-memory database is a very useful technique, but it limits
  your application to the minimum features are common to both database engines. If
  you're not using an ORM you can maintain complete test coverage and take
  advantage of PostgreSQL features by spinning up a temporary database. In Python
  this can be automated in-process using <a
  href="https://github.com/tk0miya/testing.postgresql">ltesting.postgresql</a>

:codeblock
  :::python
  import testing.postgresql

  # Temporary Database

  def init_postgres():
      postgresql = testing.postgresql.Postgresql()
      print "postgresql up and running at %s" % postgresql.url()
      return postgresql

  def setup_static_fetch(postgresql):
      subprocess.check_output(['psql', postgresql.url(), '-q', '-f', 'schema.sql'])

  # Initialize App

  postgresql = init_postgres()
  setup_static_fetch(postgresql)

  import app

%p
  Now we can start to write unit tests using this new ephemeral database. This
  is how one might set up a <a href="http://www.tornadoweb.org/">Tornado</a>
  application

:codeblock
  :::python
  import unittest
  import psycopg2
  from tornado.options import options
  from tornado.testing import AsyncHTTPTestCase, LogTrapTestCase

  class TestUI(AsyncHTTPTestCase, LogTrapTestCase):

      @classmethod
      def setUpClass(cls):
          app.application.db = psycopg2.connect(options.dsn)
          app.application.db.set_isolation_level( \
                  psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)

      @classmethod
      def tearDownClass(cls):
          if not app.application.db.closed:
              app.application.db.close()

      def get_app(self):
          return app.application

      def setUp(self):
          # use db connection from server to make trasactions are effective
          self.cur = app.application.db.cursor()
          self.cur.execute("BEGIN;")
          super(TestUI, self).setUp()

      def tearDown(self):
          self.cur.execute("ROLLBACK;")
          self.cur.close()
          super(TestUI, self).tearDown()

%p
  And our first test

:codeblock
  :::python
      def test_list_urls(self):
          self.http_client.fetch(self.get_url("/"), self.stop)
          response = self.wait()
          self.assertEqual(response.code, 200)

  if __name__ == '__main__':
      options.dsn = postgresql.url()
      unittest.main()

%h2
  Time-Limited Database Instances

%p
  In Python there are some tricky edge cases that can easily hang the test
  runner if an uncaught exception occurs while running the unit tests. One
  solution is to spin up the database in a separate daemon:

:codeblock
  :::python
  #!/usr/bin/env python

  import time
  import daemon
  import testing.postgresql

  def wait(seconds=60):
      time.sleep(seconds)

  if __name__ == "__main__":
      postgresql = testing.postgresql.Postgresql()
      print postgresql.url()
      with daemon.DaemonContext():
          wait()

%p
  With the help of a simple script, the <a
  href="https://metacpan.org/release/TJC/Test-PostgreSQL-0.10">Test::PostgreSQL</a>
  Perl module can also be used to quickly spin up a database before running
  tests:

:codeblock
  :::perl
  #!/usr/bin/env perl

  use strict;
  use warnings;

  use Test::PostgreSQL;
  use Proc::Daemon;

  my $pgsql = Test::PostgreSQL->new();
  print $pgsql->uri, "\n";

  Proc::Daemon::Init;
  sleep(30);

%p
  In both cases the library will automatically stop and remove the temporary
  database after a period of five minutes. Not only is this technique robust, but
  it can be used from any language, including a test runner written in shell

:codeblock
  :::sh
  #!/bin/sh
  url=$(./startpg.py)
  psql -f schema.sql $url
  # ...

%h2
  Responsive Testing

%p
  It takes less then ten seconds to initialize a new database and start
  Postgres, but it would be huge boot to efficiency if it was available in less
  then one second.  To accomplish this I published a utility called
  <em>pg_tmp</em> at <a href="http://ephemeralpg.org">ephemeralpg.org</a>. This
  example uses ruby:

:codeblock
  :::ruby
  require 'pg'
  require 'rubypgurl'

  spec = RubyPgURL.parse(`pg_tmp -t`)
  puts "Using \#{spec}"
  conn = PG.connect(spec)
  result = conn.exec("SELECT 1 AS number")
  for row in result do
      print row['number']
  end

%p
  <em>pg_tmp</em> uses several tricks to reduce the wait time for a new
  database to less than a second. The temporary database will be garbage-collected
  asynchronously. By default <em>pg_tmp</em> returns the path to a Unix socket,
  but an unused TCP port can be selected instead using the <em>-t</em> option.
  This is nessesary for <a
  href="http://stackoverflow.com/questions/13771968/minimal-postgres-instance-for-testing/24619189#24619189">Java</a>
  since Unix sockets are not supported.

