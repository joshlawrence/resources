<!DOCTYPE html>
<html>
<head>
<title>
Failover Orchestration for PostgreSQL</h2>

</title>
<meta content='text/html; charset=US-ASCII' http-equiv='Content-Type'>
<link href='../main.css' rel='stylesheet' type='text/css'>
<link href='../code.css' rel='stylesheet' type='text/css'>
</head>
<body>
<h3 style='margin-left: 5px; margin-top: 20px;'>
<a href='../index.html' id='myname'>Eric Radman</a>
<span id='mytitle'>: a Journal</span>
</h3>
<div id='article'>
<h2>Failover Orchestration for PostgreSQL</h2>
<h2>Ground Rules</h2>
<p>
The strong-consistory guarantees of a relational database does not generally
lead to an architecture conducive to easy migration. Elaborate mechanisms can
be conceived of to handle hot failover with PostgreSQL, but if there is one
lesson that we can take away from Computer Science it is that the key to
solving complex problems is to make assertions.
</p>
<p>
For this exercise we will use the following rules:
</p>
<ol>
<li>
Read-write connections are handled by a proxy (port 6432). By insisting that
update operations run through a proxy we can instantly redirect transactions
to a new backend while we wait for DNS to converge. The proxy also enables
us to pause connections for the 5-8 seconds it will take to transition to a
new master.
</li>
<li>
Read-only connections are handled directly by postgres (port 5432).
Applications that only need to read data will continue to operate on a
standby that was promoted as a master. Again until DNS or some other
mechanism shifts this load back to the new standby.
</li>
<li>
Only one master is enabled at any given point in time. If we never have
concurrent writes timelines will not diverge, eliminating the need to run a
rewind.
</li>
</ol>
<h2>The Salt Framework</h2>
<p>
For our basic salt configuration we will add two entries to
<em>/etc/salt/master</em>:
</p>
<p></p>
<pre>&#x000A;<span class="Identifier">file_roots</span><span class="Special">:</span>&#x000A;  <span class="Identifier">base</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span>/home/eradman/salt&#x000A;&#x000A;<span class="Identifier">pillar_roots</span><span class="Special">:</span>&#x000A;  <span class="Identifier">base</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span>/home/eradman/salt/pillar&#x000A;</pre>
<p>
Where <em>file_roots</em> defines where to look for our state files, and
<em>pillar_roots</em> defines where state files that define global variables
are located.
</p>
<pre>&#x000A;<span class="Comment"># top.sls</span>&#x000A;<span class="PreProc">{{saltenv}}</span>:&#x000A;  <span class="Constant">'</span><span class="Constant">pgdb*</span><span class="Constant">'</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span>postgres&#x000A;</pre>
<pre>&#x000A;<span class="Comment"># pillar/top.sls</span>&#x000A;<span class="PreProc">{{saltenv}}</span>:&#x000A;  <span class="Constant">'</span><span class="Constant">*</span><span class="Constant">'</span><span class="Special">:</span>&#x000A;    <span class="Identifier">pg</span><span class="Special">:</span>&#x000A;      <span class="Identifier">mydb</span><span class="Special">:</span>&#x000A;        <span class="Identifier">writer</span><span class="Special">:</span> pgdb1&#x000A;        <span class="Identifier">query</span><span class="Special">:</span> pgdb2&#x000A;&#x000A;    <span class="Identifier">pg_replication_map</span><span class="Special">:</span>&#x000A;      <span class="Identifier">pgdb2</span><span class="Special">:</span> pgdb1&#x000A;</pre>
<p>
Now we will give salt some directions for managing our PostgreSQL instances
using the static pillar data we defined.
</p>
<pre>&#x000A;<span class="Comment"># postgres/init.sls</span>&#x000A;<span class="PreProc">{% </span><span class="Statement">if</span><span class="PreProc"> grains.host </span><span class="Statement">in</span><span class="PreProc"> [pillar.pg.mydb.query] %}</span>&#x000A;<span class="Identifier">/pg_data/9.5/recovery.conf</span><span class="Special">:</span>&#x000A;  <span class="Identifier">file.managed</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span><span class="Identifier">user</span><span class="Special">:</span> postgres&#x000A;    <span class="Statement">- </span><span class="Identifier">group</span><span class="Special">:</span> postgres&#x000A;    <span class="Statement">- </span><span class="Identifier">source</span><span class="Special">:</span> salt://postgres/recovery.conf.j2&#x000A;    <span class="Statement">- </span><span class="Identifier">user</span><span class="Special">:</span> postgres&#x000A;    <span class="Statement">- </span><span class="Identifier">group</span><span class="Special">:</span> postgres&#x000A;    <span class="Statement">- </span><span class="Identifier">template</span><span class="Special">:</span> jinja&#x000A;    <span class="Statement">- </span><span class="Identifier">context</span><span class="Special">:</span>&#x000A;      <span class="Identifier">restore_cmd</span><span class="Special">:</span> <span class="Constant">'</span><span class="Constant">scp </span><span class="PreProc">{{pillar.pg_replication_map[grains.host]}}</span><span class="Constant">:/pg_data/</span><span class="PreProc">{{pgver}}</span><span class="Constant">/pg_xlog/%f</span>&#x000A;&#x000A;<span class="PreProc">{% </span><span class="Statement">else</span><span class="PreProc"> %}</span>&#x000A;<span class="Identifier">promote_new_master</span><span class="Special">:</span>&#x000A;  <span class="Identifier">cmd.run</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span><span class="Special">name</span><span class="Special">:</span> <span class="Constant">'</span><span class="Constant">/usr/pgsql-9.5/bin/pg_ctl promote -D /pg_data/9.5</span><span class="Constant">'</span>&#x000A;    <span class="Statement">- </span><span class="Special">onlyif</span><span class="Special">:</span> <span class="Constant">'</span><span class="Constant">test -e /pg_data/9.5/recovery.conf</span><span class="Constant">'</span>&#x000A;    <span class="Statement">- </span><span class="Identifier">runas</span><span class="Special">:</span> postgres&#x000A;<span class="PreProc">{% </span><span class="Statement">endif</span><span class="PreProc"> %}</span>&#x000A;&#x000A;<span class="Identifier">postgresql-9.5</span><span class="Special">:</span>&#x000A;  <span class="Identifier">service.running</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span><span class="Identifier">enable</span><span class="Special">:</span> <span class="Constant">True</span>&#x000A;</pre>
<p>
Each standby will install <em>recovery.conf</em>, which will be rendered with
context from <em>postgres/init.sls</em>
</p>
<pre>&#x000A; <span class="Comment"> # postgres/recovery.conf.j2</span>&#x000A;  standby_mode = <span class="Constant">'</span><span class="Constant">on</span><span class="Constant">'</span>&#x000A;  primary_conninfo = <span class="Constant">'</span><span class="Constant">user=postgres host=</span><span class="PreProc">{{ pillar.pg_replication_map[grains.host] }}</span><span class="Constant">'</span>&#x000A;  recovery_target_timeline = <span class="Constant">'</span><span class="Constant">latest</span><span class="Constant">'</span>&#x000A;  restore_command = <span class="Constant">'</span><span class="PreProc">{{restore_cmd}}</span><span class="Constant">'</span>&#x000A;</pre>
<p>
Here a database is either a standby (query) or it is a master (writer). If
it is a standby we install </em>recovery.conf</em>.
<em>recovery_target_timeline</em> is an important parameter because it
allows a standby to automatically follow a new timeline.
</p>
<p>
If the host is  not a standby but <em>recovery.conf</em> is found on the
file system then we know a transition is taking place and we promote the
server. In any case we ensure that the service is running. We can test to
see what actions will be taken on each host individually:
</p>
<pre>&#x000A;salt 'pgdb1*' state.highstate saltenv=eradman test=True&#x000A;salt 'pgdb2*' state.highstate saltenv=eradman test=True&#x000A;</pre>
<h2>Redirection</h2>
<p>
PgBouncer has the very nice property of pausing connections if the backend
(the postgresql server) is not responding). By shutting down the former
master we also avoid the danger of stray WAL statements during this
transition.
</p>
<p>
To reconfigure pgbouncer we re-write <em>pgbouncer.ini</em> and signal a
configuration change
</p>
<pre>&#x000A;<span class="Comment"># postgres/init.sls</span>&#x000A;<span class="Identifier">/etc/pgbouncer/pgbouncer.ini</span><span class="Special">:</span>&#x000A;  <span class="Identifier">file.managed</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span><span class="Identifier">source</span><span class="Special">:</span> salt://postgres/pgbouncer.ini.j2&#x000A;    <span class="Statement">- </span><span class="Identifier">template</span><span class="Special">:</span> jinja&#x000A;&#x000A;kill -HUP `cat /var/run/pgbouncer/pgbouncer.pid`:&#x000A;  <span class="Identifier">cmd.run</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span><span class="Identifier">runas</span><span class="Special">:</span> pgbouncer&#x000A;    <span class="Statement">- </span><span class="Special">onchanges</span><span class="Special">:</span>&#x000A;      <span class="Statement">- </span><span class="Identifier">file</span><span class="Special">:</span> /etc/pgbouncer/pgbouncer.ini&#x000A;</pre>
<p>
Now in <em>pgbouncer.ini</em> we add some conditional configuration to point
to a local UNIX socket or to a remote host. In this way connections to the
proxy are always routed to a server that has write access.
</p>
<pre>&#x000A;<span class="Special">[</span>databases<span class="Special">]</span>&#x000A;; local unix connections&#x000A;<span class="PreProc">{% </span><span class="Statement">if</span><span class="PreProc"> grains.host </span><span class="Statement">in</span><span class="PreProc"> [pillar.pg.mydb.writer] -%}</span>&#x000A;database1 =&#x000A;database2 =&#x000A;<span class="PreProc">{% </span><span class="Statement">endif</span><span class="PreProc"> %}</span>&#x000A;&#x000A;; redirections to current master&#x000A;<span class="PreProc">{%- </span><span class="Statement">if</span><span class="PreProc"> grains.host == pillar.pg.mydb.query %}</span>&#x000A;* = host=<span class="PreProc">{{ pillar.pg.mydb.writer }}</span>&#x000A;<span class="PreProc">{%- </span><span class="Statement">endif</span><span class="PreProc"> %}</span>&#x000A;&#x000A;&#x000A;</pre>
<h2>Orchestration</h2>
<p>
Once we have the building blocks in place for connecting a stanby to the
current master and promoting a stanby to a master we need to execute these in
the right order. A schell script could do or we can use Salt's
<em>state.orchestrate</em> module, which provides both sequential execution
and the ability to specify dependencies.
</p>
<pre>&#x000A;<span class="Identifier">stop_former_master</span><span class="Special">:</span>&#x000A;  <span class="Identifier">salt.function</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span><span class="Special">name</span><span class="Special">:</span> cmd.run&#x000A;    <span class="Statement">- </span><span class="Identifier">tgt</span><span class="Special">:</span> <span class="PreProc">{{pillar.pg.mydb.query}}</span>*&#x000A;    <span class="Statement">- </span><span class="Identifier">arg</span><span class="Special">:</span>&#x000A;      <span class="Statement">- </span>systemctl stop postgresql-9.5&#x000A;&#x000A;<span class="Identifier">promote_master</span><span class="Special">:</span>&#x000A;  <span class="Identifier">salt.state</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span><span class="Identifier">tgt</span><span class="Special">:</span> <span class="PreProc">{{pillar.pg.mydb.writer}}</span>*&#x000A;    <span class="Statement">- </span><span class="Identifier">highstate</span><span class="Special">:</span> <span class="Constant">True</span>&#x000A;&#x000A;<span class="Identifier">rejigger_replicas</span><span class="Special">:</span>&#x000A;  <span class="Identifier">salt.state</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span><span class="Identifier">tgt</span><span class="Special">:</span> <span class="PreProc">{{pillar.pg.mydb.query}}</span>*&#x000A;    <span class="Statement">- </span><span class="Identifier">highstate</span><span class="Special">:</span> <span class="Constant">True</span>&#x000A;</pre>
<p>
That is the core of it, I also like to finish with a command that gives a
one-line status of the new master's WAL status:
</p>
<pre>&#x000A;<span class="Identifier">mydb.writer_status</span><span class="Special">:</span>&#x000A;  <span class="Identifier">salt.function</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span><span class="Special">name</span><span class="Special">:</span> cmd.run&#x000A;    <span class="Statement">- </span><span class="Identifier">tgt</span><span class="Special">:</span> <span class="PreProc">{{pillar.pg.mydb.writer}}</span>*&#x000A;    <span class="Statement">- </span><span class="Identifier">arg</span><span class="Special">:</span>&#x000A;      <span class="Statement">- </span>|&#x000A;        psql -U postgres &lt;&lt;SQL&#x000A;           SELECT pg_xlogfile_name(pg_last_xlog_replay_location());&#x000A;        SQL</pre>
<br />
<p>
That everything! Initiate failover using
</p>
<pre>&#x000A;$EDITOR pillar/globals.sls&#x000A;sudo salt-run state.orchestrate postgres-failover.mydb saltenv=$USER&#x000A;</pre>
<h2>Log Messages</h2>
<p>Transition to master:</p>
<pre>&#x000A;LOG:  received promote request&#x000A;LOG:  redo done at 32/39225840&#x000A;LOG:  last completed transaction was at log time 2016-12-01 10:30:52.907917-05&#x000A;LOG:  selected new timeline ID: 2&#x000A;LOG:  archive recovery complete&#x000A;LOG:  MultiXact member wraparound protections are now enabled&#x000A;LOG:  checkpoint starting: force&#x000A;LOG:  autovacuum launcher started&#x000A;</pre>
<p>Transition to standby:</p>
<pre>&#x000A;LOG:  entering standby mode&#x000A;LOG:  consistent recovery state reached at 32/392258B0&#x000A;LOG:  invalid record length at 32/392258B0&#x000A;LOG:  database system is ready to accept read only connections&#x000A;LOG:  fetching timeline history file for timeline 2 from primary server&#x000A;LOG:  started streaming WAL from primary at 32/39000000 on timeline 1&#x000A;DETAIL:  End of WAL reached on timeline 1 at 32/392258B0.&#x000A;LOG:  new target timeline is 2&#x000A;LOG:  replication terminated by primary server&#x000A;LOG:  restarted WAL streaming at 32/39000000 on timeline 2&#x000A;LOG:  redo starts at 32/392258B0&#x000A;</pre>
<h2>A Replication View</h2>
<p>
Another aspect of replication and failover the is not obvious is how to
collect meaningful information about the status of database replicas. Making
this inquiry efficient is more important as the number of databases servers
grows.
</p>
<p>
Again Salt helps because we can collect the list of involved hosts to run
against
</p>
<pre>&#x000A;<span class="PreProc">{% set hosts = pillar.pg.mydb.values()|</span><span class="Identifier">join</span><span class="PreProc">(</span><span class="Constant">&quot;|&quot;</span><span class="PreProc">) %}</span>&#x000A;</pre>
<p>
Now we can find out the basic status of replication connections
</p>
<pre>&#x000A;<span class="Identifier">mydb_replication_status</span><span class="Special">:</span>&#x000A;  <span class="Identifier">salt.function</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span><span class="Special">name</span><span class="Special">:</span> cmd.run&#x000A;    <span class="Statement">- </span><span class="Identifier">tgt</span><span class="Special">:</span> <span class="Constant">'</span><span class="PreProc">{{hosts}}</span><span class="Constant">'</span>&#x000A;    <span class="Statement">- </span><span class="Identifier">tgt_type</span><span class="Special">:</span> pcre&#x000A;    <span class="Statement">- </span><span class="Identifier">arg</span><span class="Special">:</span>&#x000A;      <span class="Statement">- </span>|&#x000A;        echo&#x000A;        psql -U postgres &lt;&lt;SQL&#x000A;          SELECT&#x000A;            application_name, client_addr, state, sent_location, replay_location, sync_state&#x000A;          FROM pg_stat_replication;&#x000A;        SQL</pre>
<br />
<p>
Execute by running the SLS
</p>
<pre>&#x000A;$ sudo salt-run state.sls mydb-status&#x000A;</pre>
<p>
A more in-depth view of reply status can be obtained from the
<em>pg_control_checkpoint</em> view, which was introduced in 9.6
</p>
<pre>&#x000A;<span class="Identifier">qmdb_replay_status</span><span class="Special">:</span>&#x000A;  <span class="Identifier">salt.function</span><span class="Special">:</span>&#x000A;    <span class="Statement">- </span><span class="Special">name</span><span class="Special">:</span> cmd.run&#x000A;    <span class="Statement">- </span><span class="Identifier">tgt</span><span class="Special">:</span> <span class="Constant">'</span><span class="PreProc">{{hosts}}</span><span class="Constant">'</span>&#x000A;    <span class="Statement">- </span><span class="Identifier">tgt_type</span><span class="Special">:</span> pcre&#x000A;    <span class="Statement">- </span><span class="Identifier">arg</span><span class="Special">:</span>&#x000A;      <span class="Statement">- </span>|&#x000A;        echo&#x000A;        psql -U postgres &lt;&lt;SQL&#x000A;          SELECT&#x000A;            pg_last_xlog_receive_location() receive_location,&#x000A;            pg_last_xlog_replay_location() replay_location,&#x000A;            redo_wal_file, timeline_id, next_xid,&#x000A;            date_trunc('second', now()-checkpoint_time) AS last_checkpoint,&#x000A;            CASE WHEN pg_is_in_recovery()='t'&#x000A;              THEN date_trunc('seconds', now()-pg_last_xact_replay_timestamp())&#x000A;            END AS last_xact_replay&#x000A;          FROM pg_control_checkpoint();&#x000A;        SQL</pre>
<br />
<p>
For standard standby servers this will enable you to verify that all of the
database servers are running on the same timeline, that they have not fallen
behind, and for delayed replicas you can verify that they are running behind
with the prescribed delay. In this example mydb3 has
<em>recovery_min_apply_delay = '1d'</em> set in <em>recovery.conf</em>
</p>
<pre>&#x000A;      ID: mydb_replay_status&#x000A;Function: salt.function&#x000A;    Name: cmd.run&#x000A;  Result: True&#x000A; Comment: Function ran successfully. Function cmd.run ran on mydb1, mydb2, mydb3.&#x000A; Started: 16:12:50.445661&#x000A;Duration: 5072.736 ms&#x000A; Changes:&#x000A;&#x000A;          mydb1:&#x000A;           receive_location | replay_location |      redo_wal_file       | timeline_id |  next_xid  | last_checkpoint | last_xact_replay&#x000A;          ------------------+-----------------+--------------------------+-------------+------------+-----------------+------------------&#x000A;           EB/6FF5B540      | EB/6FF5B540     | 00000003000000EB0000006F |           3 | 0:33686826 | 00:08:21        | 00:00:12&#x000A;          (1 row)&#x000A;&#x000A;          mydb2:&#x000A;           receive_location | replay_location |      redo_wal_file       | timeline_id |  next_xid  | last_checkpoint | last_xact_replay&#x000A;          ------------------+-----------------+--------------------------+-------------+------------+-----------------+------------------&#x000A;                            |                 | 00000003000000EB0000006F |           3 | 0:33686826 | 00:03:21        |&#x000A;          (1 row)&#x000A;&#x000A;          mydb3:&#x000A;           receive_location | replay_location |      redo_wal_file       | timeline_id |  next_xid  | last_checkpoint | last_xact_replay&#x000A;          ------------------+-----------------+--------------------------+-------------+------------+-----------------+------------------&#x000A;           EB/6FF5B540      | EA/C87286A0     | 00000003000000EA000000C7 |           3 | 0:33656828 | 1 day 00:09:50  | 1 day 00:00:02&#x000A;          (1 row)</pre>

</div>
<p class='timestamp'>
Last updated on May 18, 2017
</p>
</body>
</html>
